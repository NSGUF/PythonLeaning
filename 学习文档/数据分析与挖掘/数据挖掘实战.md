# 第1章 数据挖掘基础
>**概念：**从大量数据中挖掘出隐含的、未知的、对决策有潜在价值的关系、模式、趋势，并用这些知识和规则建立用于决策支持的模型，提供预测性决策支持的方法、工具和过程，就是**数据挖掘**；是利用各种分析工具在大量数据中寻找其规律和发现模型与数据之间关系的过程，是统计学、数据库技术和人工智能技术的综合。  
>**基本任务：**利用分类与预测、聚类分析、关联规则、时序模式、偏差监测、智能推荐等方法，帮助企业提取数据中蕴含的商业价值，提高企业竞争能力。  
>**数据挖掘建模过程：**  
>1、定义挖掘目标；  
>2、数据取样，常用有：随机、等距、分层、从起始顺序、分类；  
>3、数据探索，主要有：异常值分析、缺失值分析、相关分析和周期性分析等。  
>4、数据预处理：主要有：数据筛序、数据变量转换、缺失值处理、坏数据处理、数据标准化、主成分分析、属性选择、数据违约等；  
>5、挖掘建模；  
>6、模型评价；
# 第2章 Python数据分析简介  
* [python学习笔记](http://www.cnblogs.com/NSGUF/p/7459427.html)  
* [Numpy学习笔记](http://www.cnblogs.com/NSGUF/p/7406027.html)  
* [Scipy学习笔记](http://www.cnblogs.com/NSGUF/p/7406027.html)  
* [Matplotlib学习笔记](http://www.cnblogs.com/NSGUF/p/7406027.html)  
* [Pandas学习笔记](http://www.cnblogs.com/NSGUF/p/8127673.html)  
* [StatsModels学习笔记](http://www.cnblogs.com/NSGUF/p/7406027.html)  
* Scikit-Learn  
	>该库包括数据预处理、分类、回归、聚类、预测和模型分析等。使用方法如下：  
	  
		# 1、导入模型
		from sklearn.linear_model import LinearRegression
		# 创建对象
		model=LinearRegression()
		# 所有模型提供的接口有
		model.fit()# 训练模型
		# 监督模型提供的接口有
		model.predict(X_new)# 预测新样本
		model.predict_proba(X_new)# 预测概率，仅对某些模型有用如：LR
		model.score()# 得分越高，fit越好
		# 非监督模型提供的接口有
		model.transforms()# 从数据中学到新的“基空间”
		model.transforms()# 从数据中学到新的“基空间”并将这个数据按照数组‘基’进行转换
* [Keras学习笔记](http://www.cnblogs.com/NSGUF/p/7406027.html)  
# 第3章 数据探索
>**概念：**通过检验数据集的数据质量、绘制图标、计算某些特征向量等手段，对样本数据集的结构和规律进行分析的过程。
## 3.1 数据质量分析
>该过程是数据预处理的前提，也是数据挖掘分析结论有效性和准确性的基础。  
>数据质量分析的主要目的是检查原始数据中是否存在脏数据，脏数据包括以下：    
>
* 缺失值  
* 异常值
* 不一致的值
* 重复数据及含有特殊符号（如#、￥、*）等数据  

### 3.1.1 缺失值分析
1、产生原因：  
    1）某些信息无法被获取或获取信息代价太大。  
    2）被遗漏。  
    3）属性值不存在。  
2、缺失值的影响：  
1）丢失大量的有用信息。  
2）模型中所蕴含的规律更难把握。  
3）导致不可靠输出。  
3、缺失值的分析：  
统计含有缺失值属性的个数以及每个属性的未缺失数、缺失数与缺失率。  
4、缺失值处理：  
1）删除存在的缺失值。  
2）对可能进行插补。  
3）不处理。
### 3.1.2 异常值分析  
>异常值是指样本中的个别值，其数值明显偏离其余的观测值。异常值也成为**离群值**，异常值分析也称为离群点分析。  
1.简单统计量分析：变量取值是否合理，如年龄不超过200。  
2.3σ原则：若数据服从正态分布，在3σ原则下，异常值为测定值与平均值的偏差超过3倍标准差的值。若不服从，则用远离平均值的多少倍标准差来描述。  
3.箱型图分析：异常值被定义为小于Q<sub>l</sub>-1.5IQR或大于Q<sub>u</sub>+1.5IQR的值。Q<sub>l</sub>称为下四分位数，表示全部观察值中有四分之一的数据取值比它小；Q<sub>u</sub>称为上四分位数，表示全部观察值中有四分之一的数据取值比它大；IQR称为四分位数间距是Q<sub>l</sub>与Q<sub>u</sub>的差值，期间包含了全部观察值的一半。箱型图识别异常值的结果比较客观，在识别异常值方面有一定的优越性。下面给出一个例子：

	# 异常值检查
	import pandas as pd
	import matplotlib.pyplot as plt
	catering_sale='catering_sale.xls' # 餐饮数据
	data=pd.read_excel(catering_sale,index_col='日期')# 读取数据并指定列为日期
	print(data.describe())# 打印出数据的基本数据，count表示非空值数
	print(len(data))# 总共条数
	
	plt.figure()
	p=data.boxplot(return_type='dict')# 画箱型图
	x=p['fliers'][0].get_xdata()
	y=p['fliers'][0].get_ydata()
	y.sort()
	for i in range(len(x)):
	    if i>0:
	        plt.annotate(y[i],xy=(x[i],y[i]),xytext=(x[i]+0.05-0.8/(y[i]-y[i-1]),y[i]))
	    else:
	        plt.annotate(y[i], xy=(x[i], y[i]), xytext=(x[i] + 0.8, y[i]))
	plt.show()

### 3.1.3 一致性分析
>数据不一致性是指数据的矛盾性和不相容性。产生原因主要发生在数据集成的过程中，这可能是由于被挖掘数据是来自于从不同的数据源、对于重复存放的数据未能进行一致性更新。例如两张表中都存储了用户的电话，但在用户的电话发生改变时，只更新了一张表的数据，那么这两张表中就有了不一致的数据。
## 3.2数据特征分析
### 3.2.1 分布分析  
>分布分析可以揭示数据的分布特征和分布类型。对于定量数据，想要了解其分布形式是对称还是非对称，发现某些特大特效的可疑值，可通过绘制频率分布表和频率分布直方图、茎叶图进行直观观察；对于定性分类数据，可用饼状图和条形图直观地显示分布情况。  

**1、定量数据的分布分析**  
1）求极差：最大值-最小值  
2）决定组距和组数：组数=极差/组距  
3）决定分点：分布区间  
4）绘制频率分布表  
5）绘制频率分布直方图  
**2、定性数据的分布分析**  
根据变量的分类类型来分组，可采用饼图和条形图。
### 3.2.2 对比分析
>对比分析是把两个相互关联的指标进行比较，从数量上展示和说明研究对象规模的大小、水平的高低、速度的快慢，以及各种关系是否协调。特别适用于指标间的横纵向比较、时间序列的比较分析。对比分析主要有两种形式：
（1）绝对数比较：绝对数比较是利用绝对数进行比较。
（2）相对数比较：由两个有联系的指标对比计算，用以客观现象之间数量联系程度的综合指标，其数值表现为相对数。由于研究目的和对比基础不同，相对数可以分为以下几种：  
1）结构相对数：将同一总体内的部分数值与全部数值对比求得比重，用以说明事物的性质、结构或质量。如合格率  
2）比例相对数：将同一总体内不同部分的数值进行对比，表明总体内各部分的比例关系。如男女比例  
3）比较相对数：将同一时期两个性质相同的指标数值进行对比，说明同类现象在不同空间下的数量对比关系。如不同地区上品价格比  
4）强度相对数：将两个性质不同但有一定联系的总量指标进行对比，用以说明现象强度、密度和普遍程度。如人均国内生产总值  
5）计划完成程度相对数：某一时期实际完成数与计划书的对比，用以说明计划完成程度。  
6）动态相对数：将同一现象在不同时期的指标数值进行对比，用以说明发展方向和变化速度。如增长速度  
### 3.2.3 统计量分析  
>用统计指标对定量数据进行统计描述。  
**1、集中趋势度量**  
1）均值，若不同成分所占的不同重要程度，可为数据集的每个值都添加一个权重；若数据中存在极端值或数据是偏态分布，那么均值便不能很好地度量数据的集中趋势，为了消除少数极端值的影响，可以使用截断均值或中位数来度量数据的及中国趋势。截断均值是去除高、低极端值之后的平均数。  
2）中位数：数据集中的值从小到大排序，位于中间的数。当数据个数为偶数，则是中间两个数的平均值。  
3）众数：指数据集中出现最频繁的值；众数不经常用来度量定性变量的中心位置，更适合用于定性变量。众数不具有唯一性，一般用于离散型变量而非连续性变量。  
**2、离中趋势度量**  
1）极差  
2）标准差：度量数据偏离均值的程度  
3）异变系数：度量标准差相对于均值的离中趋势；值为（标准差/平均值），主要用来比较两个或多个具有不同单位或不同波动幅度的数据集的离中趋势。  
4）四分位数间距：将所有数值从小到大排列分为四等份，处于第一个分割点的是下四分位，第二个分割点位位于中位数的位置，第三个分割点位置的数值是上四分位数。四分位间距是上四分位和下四分位的差值，其值越大，说明数据的变异程度越大，反之，越小。  
餐饮数据统计量分析例子如下：  

	import pandas as pd
	catering_scale='catering_sale.xls'
	data=pd.read_excel(catering_scale,index_col='日期')
	data=data[(data['销量']>400)&(data['销量']<5000)]# 过滤异常值
	
	statistics=data.describe()# 获取结果
	
	statistics.loc['range']=statistics.loc['max']-statistics.loc['min']# 添加极值
	statistics.loc['var']=statistics.loc['std']-statistics.loc['mean']# 添加异变系数
	statistics.loc['dis']=statistics.loc['75%']-statistics.loc['25%']# 四分位间距
	print(statistics)

### 3.2.4 周期性分析  
>探索某个变量是否随时间变化而呈现出某种周期变化趋势。时间尺度相对较长的周期性趋势有年度周期性趋势、季节性周期趋势，相对较短的有月度周期性趋势、周度周期性趋势，甚至更短的天、小时周期性趋势。
### 3.2.5 贡献度分析  
>贡献度分析又称帕累托分析，原理来自帕累托法则，又称20/80定律。重点改善盈利最高的前80%，可增加盈利。给出画帕累托的例子：  

	import pandas as pd
	import matplotlib.pyplot as plt
	
	catering_dish = 'catering_dish_profit.xls'
	data = pd.read_excel(catering_dish, index_col='菜品名')  # 读取信息
	print(data)
	data = data['盈利'].copy()
	
	data = data.sort_values(ascending=False)  # 对盈利倒序
	
	plt.figure()
	data.plot(kind='bar')
	p = 1.0 * data.cumsum() / data.sum()# 比例
	p.plot(color='r', secondary_y=True, style='-o', linewidth=2)
	plt.annotate(format(p[6], '.4%'), xy=(6, p[6]), xytext=(6 * 0.9, p[6] * 0.9),
	             arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=.2"))  # 添加注释，即85%处的标记。这里包括了指定箭头样式。
	plt.show()

### 3.2.6 相关性分析 
>分析连续变量之间线性相关程度的强弱，并用适当的统计指标表示出来的过程称为相关分析。  
**1.直接绘制散点图**    
判断两个变量是否具有线性相关关系的最直观方法是直接绘制散点图。  
**2.绘制散点图矩阵**  
若需要同时考察多个变量间的相关关系时，一一绘制他们间的简单散点图是十分麻烦的。此时可利用散点图矩阵同时绘制各变量间的散点图，从而快速发现多个变量间的主要相关性。在多元线性回归有重要作用。  
**3.计算相关系数**    
为了更加准确地描述变量之间的线性相关程度，可通过计算相关系数进行相关分析。  
1）Pearson相关系数，一般用于分析两个连续性变量之间的关系，要求服从正态分布：  
![](http://img.my.csdn.net/uploads/201211/21/1353507674_8005.png)   
相关系数r的取值范围：-1<=r<=1;  
0<|r|<1表示存在不同程度线性相关：  
若0.3<|r|<=0.5 低度线性相关    
若0.5<|r|<=0.8 显著线性关系  
若|r|>0.8 高度线性关系  
2）Spearman秩相关系数，不服从正态分布的变量、分类或等级变量之间的关联性。   
只要两个变量具有严格单调的函数关系，那么他们就是完全Spearman相关，这与Pearson相关不同，Pearson相关只有在变量具有线性关系时才完全相关。研究表明，在正态分布假定的情况下，Spearman秩相关系数与Pearson相关系数在效率上等价，而对于连续测量数据，更适合用Pearson相关系数来进行分析。  
3）判定系数  
判定系数是相关系数的平方，用r<sup>2</sup> 表示；用来衡量回归方程对y的解释程度。判定系数取值范围：0<=r<sup>2</sup><=1。r<sup>2</sup>越接近1，表明x与y之间的相关性越强；反之月接近0，表明两个变量之间几乎没有直线相关关系。  

	# 不同菜品之间的关系
	import pandas as pd
	
	data=pd.read_excel('catering_sale_all.xls',index_col='日期') 
	print(data.corr())# 相关系数矩阵，即给出了任意两个菜之间的关系  Spearman(Pearman)
	print(data.corr()['百合酱蒸凤爪']) # 给出了百合酱蒸凤爪与其他任意菜之间的关系

## 3.3 Python主要数据探索函数  












